{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "\n",
    "MU=pd.read_csv(open('MU-geo.csv','rU'),sep=',')\n",
    "MC=pd.read_csv(open('MC-geo.csv','rU'),sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    (\"What an awesome view\", 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The beer was amazing. \"\n",
    "                \"But the hangover was horrible. My boss was not happy.\",\n",
    "                classifier=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MU['sentiment']=0\n",
    "MC['sentiment']=0\n",
    "MU['pos']=0\n",
    "MC['pos']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n"
     ]
    }
   ],
   "source": [
    "#for total\n",
    "for i in range(len(MU)):\n",
    "    text=MU['token_stop_lower'][i]\n",
    "    blob=TextBlob(text)\n",
    "    MU['sentiment'][i]=str(blob.sentiment.polarity)\n",
    "    if i%1000==0: print(i)\n",
    "    MU['pos'][i]=1 if blob.sentiment.polarity>=0 else -1\n",
    "    \n",
    "for i in range(len(MC)):\n",
    "    text=MC['token_stop_lower'][i]\n",
    "    blob=TextBlob(text)\n",
    "    MC['sentiment'][i]=str(blob.sentiment.polarity)\n",
    "    if i%1000==0: print(i)\n",
    "    MC['pos'][i]=1 if blob.sentiment.polarity>=0 else -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MC.to_csv(\"MC-sentiment.csv\",index=False,sep=',')\n",
    "MU.to_csv(\"MU-sentiment.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>geo</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>token_stop_lower</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bebzy__</td>\n",
       "      <td>RT @DeadlineDayLive: Antoine Griezemann is exp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🇬🇭 x 🇺🇸</td>\n",
       "      <td>876.0</td>\n",
       "      <td>460</td>\n",
       "      <td>Tue Nov 14 11:52:35 +0000 2017</td>\n",
       "      <td>['@deadlinedaylive', 'antoine', 'griezemann', ...</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abdulkadirsaee4</td>\n",
       "      <td>RT @DeadlineDayLive: Antoine Griezemann is exp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sarari kuka quaters katsina</td>\n",
       "      <td>46.0</td>\n",
       "      <td>335</td>\n",
       "      <td>Tue Nov 14 11:52:31 +0000 2017</td>\n",
       "      <td>['@deadlinedaylive', 'antoine', 'griezemann', ...</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheArcher94</td>\n",
       "      <td>RT @indykaila: Breaking reports that Mancheste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liverpool city</td>\n",
       "      <td>143.0</td>\n",
       "      <td>154</td>\n",
       "      <td>Tue Nov 14 11:52:22 +0000 2017</td>\n",
       "      <td>['@indykaila', 'breaking', 'reports', 'manches...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>destydan2012</td>\n",
       "      <td>@MrLukeJohnston @TheSoccerCo \"When you bring h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blues' Kingdom</td>\n",
       "      <td>752.0</td>\n",
       "      <td>970</td>\n",
       "      <td>Tue Nov 14 11:52:18 +0000 2017</td>\n",
       "      <td>['@mrlukejohnston', '@thesoccerco', 'bring', '...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trollfootbal69</td>\n",
       "      <td>Arsenal (The gooners) - Manchester united (Red...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Tue Nov 14 11:52:16 +0000 2017</td>\n",
       "      <td>['arsenal', 'gooners', 'manchester', 'united',...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gatman180</td>\n",
       "      <td>RT @ManUnitedWorld: NEXT MATCH:\\n\\n• vs Newcas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>894</td>\n",
       "      <td>Tue Nov 14 11:52:15 +0000 2017</td>\n",
       "      <td>['@manunitedworld', 'next', 'match', '•', 'vs'...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FredrickAngello</td>\n",
       "      <td>@Itubway Manchester united Cup soon to be laun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dar es Salaam, Tanzania</td>\n",
       "      <td>733.0</td>\n",
       "      <td>360</td>\n",
       "      <td>Tue Nov 14 11:52:15 +0000 2017</td>\n",
       "      <td>['@itubway', 'manchester', 'united', 'cup', 's...</td>\n",
       "      <td>0.425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AarohiS87282069</td>\n",
       "      <td>RT @JUSTIN_KlDRAUHL: SCOOTER SAID THE CONCERT ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uttar Pradesh, India</td>\n",
       "      <td>855.0</td>\n",
       "      <td>162</td>\n",
       "      <td>Tue Nov 14 11:52:14 +0000 2017</td>\n",
       "      <td>['@justin_kldrauhl', 'scooter', 'said', 'conce...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yagosabuncuoglu</td>\n",
       "      <td>@ErhanLFC83 @Futbolope Man United ponder 'sell...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Istanbul, Turkey</td>\n",
       "      <td>60897.0</td>\n",
       "      <td>265</td>\n",
       "      <td>Tue Nov 14 11:51:55 +0000 2017</td>\n",
       "      <td>['@erhanlfc83', '@futbolope', 'man', 'united',...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user                                               text  geo  \\\n",
       "1          Bebzy__  RT @DeadlineDayLive: Antoine Griezemann is exp...  NaN   \n",
       "2  Abdulkadirsaee4  RT @DeadlineDayLive: Antoine Griezemann is exp...  NaN   \n",
       "3      TheArcher94  RT @indykaila: Breaking reports that Mancheste...  NaN   \n",
       "4     destydan2012  @MrLukeJohnston @TheSoccerCo \"When you bring h...  NaN   \n",
       "5   Trollfootbal69  Arsenal (The gooners) - Manchester united (Red...  NaN   \n",
       "6        Gatman180  RT @ManUnitedWorld: NEXT MATCH:\\n\\n• vs Newcas...  NaN   \n",
       "7  FredrickAngello  @Itubway Manchester united Cup soon to be laun...  NaN   \n",
       "8  AarohiS87282069  RT @JUSTIN_KlDRAUHL: SCOOTER SAID THE CONCERT ...  NaN   \n",
       "9  yagosabuncuoglu  @ErhanLFC83 @Futbolope Man United ponder 'sell...  NaN   \n",
       "\n",
       "                      location  followers_count friends_count  \\\n",
       "1                      🇬🇭 x 🇺🇸            876.0           460   \n",
       "2  sarari kuka quaters katsina             46.0           335   \n",
       "3              Liverpool city             143.0           154   \n",
       "4               Blues' Kingdom            752.0           970   \n",
       "5                    Indonesia             84.0            15   \n",
       "6                       London           1644.0           894   \n",
       "7      Dar es Salaam, Tanzania            733.0           360   \n",
       "8         Uttar Pradesh, India            855.0           162   \n",
       "9             Istanbul, Turkey          60897.0           265   \n",
       "\n",
       "                       created_at  \\\n",
       "1  Tue Nov 14 11:52:35 +0000 2017   \n",
       "2  Tue Nov 14 11:52:31 +0000 2017   \n",
       "3  Tue Nov 14 11:52:22 +0000 2017   \n",
       "4  Tue Nov 14 11:52:18 +0000 2017   \n",
       "5  Tue Nov 14 11:52:16 +0000 2017   \n",
       "6  Tue Nov 14 11:52:15 +0000 2017   \n",
       "7  Tue Nov 14 11:52:15 +0000 2017   \n",
       "8  Tue Nov 14 11:52:14 +0000 2017   \n",
       "9  Tue Nov 14 11:51:55 +0000 2017   \n",
       "\n",
       "                                    token_stop_lower sentiment  pos  \n",
       "1  ['@deadlinedaylive', 'antoine', 'griezemann', ...     -0.05   -1  \n",
       "2  ['@deadlinedaylive', 'antoine', 'griezemann', ...     -0.05   -1  \n",
       "3  ['@indykaila', 'breaking', 'reports', 'manches...       0.2    1  \n",
       "4  ['@mrlukejohnston', '@thesoccerco', 'bring', '...       0.0    1  \n",
       "5  ['arsenal', 'gooners', 'manchester', 'united',...       0.0    1  \n",
       "6  ['@manunitedworld', 'next', 'match', '•', 'vs'...      0.05    1  \n",
       "7  ['@itubway', 'manchester', 'united', 'cup', 's...     0.425    1  \n",
       "8  ['@justin_kldrauhl', 'scooter', 'said', 'conce...       0.0    1  \n",
       "9  ['@erhanlfc83', '@futbolope', 'man', 'united',...       0.0    1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MU.iloc[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweetsnn=train_tweets[train_tweets['sentiment']<0]\n",
    "#MUp=MU[MU['sentiment']>0]\n",
    "train_tweetsnn=train_tweetsnn.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets=train_tweetsnn.iloc[0:500].append(train_tweetsn.iloc[0:487]).append(train_tweetsp.iloc[0:450])\n",
    "train_tweets=train_tweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "\n",
    "#Set to exclude punctuation marks\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "#List to exclude words that can identify the team from list of features\n",
    "excluded_words = []\n",
    "\n",
    "#Function that provides a list of filtered unigrams and bigrams from each tweet\n",
    "def filter_tweets(tweets):\n",
    "    filtered_tweets = []\n",
    "    \n",
    "    #Get a list of words, and the sentiment for each tweet\n",
    "    for i in range(len(tweets)): \n",
    "        words_filtered=[]\n",
    "        words=tweets['text'][i].split()\n",
    "        #For each word in the list of words, filter on our feature requirements. \n",
    "        for word in words: \n",
    "            word = ''.join(ch for ch in word if ch not in exclude)\n",
    "\n",
    "            #Remove zero letter \"words\"\n",
    "            if len(word) >= 1: \n",
    "                \n",
    "                    #treat URLs the same\n",
    "                    if word[:4] == 'http':\n",
    "                        word='http'\n",
    "                        \n",
    "                    #remove hashtags\n",
    "                    if word[0] == '#': \n",
    "                        word=word[1:]\n",
    "                        \n",
    "                    #remove team identifiers\n",
    "                    if (word.lower() not in excluded_words):\n",
    "        \n",
    "                        #require lower case\n",
    "                        words_filtered.append(word.lower()) \n",
    "\n",
    "        #Identify top 200 bigams in the filtered word list using chi_sq measure of importance\n",
    "        bigram_finder = BigramCollocationFinder.from_words(words_filtered)\n",
    "        bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 200)      \n",
    "\n",
    "        #Add the final bigrams and unigrams for this tweet to the filtered list\n",
    "        filtered_tweets.append(([ngram for ngram in itertools.chain(words_filtered, bigrams)],tweets['sentiment'][i]))\n",
    "\n",
    "    #Returnt he filtered list for all tweets\n",
    "    return filtered_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets = filter_tweets(train_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_word_features(tweets,min_freq):\n",
    "\n",
    "    #Create a list of ALL unigrams and bigrams\n",
    "    wordlist = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        wordlist.extend(words)\n",
    "    \n",
    "    #Count the frequency of each unigram and bigram\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    \n",
    "    #Sort the list of unigrams and bigrams based on frequency\n",
    "    sorted_word_list = sorted(wordlist.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #Only include the unigrams and bigrams as features if they appear at least min_freq times\n",
    "    word_features = [sorted_word_list[word][0] for word in \\\n",
    "    \trange(len(sorted_word_list)) if sorted_word_list[word][1] >= min_freq]\n",
    "    \n",
    "    #Return the list of features\n",
    "    return word_features\n",
    "\n",
    "word_features = get_word_features(train_tweets,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(filtered_tweet):\n",
    "\n",
    "    #list of unigrams and bigrams in the tweet\n",
    "    filtered_tweet_words = set(filtered_tweet)\n",
    "    \n",
    "    #Define a features dictionary\n",
    "    features = {}\n",
    "\n",
    "    #Loop of all word features\n",
    "    for word in word_features:\n",
    "        \n",
    "        #Set 'contains(word_feature)' as a key in the dictionary\n",
    "        #Set the value for that key to True or False\n",
    "        features['contains(%s)' % str(word)] = (word in filtered_tweet_words)\n",
    "\n",
    "    #Return the final features dictionary for that tweet\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, train_tweets)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      " contains(('it', 'was')) = True           -0.226 : 0.0    =    330.8 : 1.0\n",
      "         contains(goals) = True           -0.226 : 0.0    =    330.8 : 1.0\n",
      "         contains(silva) = True           0.4333 : 0.0    =    328.9 : 1.0\n",
      "           contains(but) = True           0.2416 : 0.0    =    327.0 : 1.0\n",
      "contains(('city', 'can')) = True           0.2416 : 0.0    =    327.0 : 1.0\n",
      "contains(('are', 'not')) = True           0.2416 : 0.0    =    327.0 : 1.0\n",
      "contains(('an', 'unstoppable')) = True           0.2416 : 0.0    =    327.0 : 1.0\n",
      "   contains(unstoppable) = True           0.2416 : 0.0    =    327.0 : 1.0\n",
      " contains(('can', 'be')) = True           0.2416 : 0.0    =    327.0 : 1.0\n",
      "      contains(mourinho) = True           -0.204 : 0.0    =    324.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
