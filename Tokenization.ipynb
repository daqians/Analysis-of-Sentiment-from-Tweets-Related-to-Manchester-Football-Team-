{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "\n",
    "consumer_key = 'UKw2KLxameeRC2eUuMJVjdnaM'\n",
    "consumer_secret = 'llDfpCz90ye74A3VL3bJdoASXMzNTTOgYyOfBWGUOnActXUYf7'\n",
    "access_token = '927148475950751746-jPlH5nynmPNLzStdmlepsmDAmHKWVGB'\n",
    "access_token_secret = '2R2P1ChKmmFsyqIMZwfOC461MPawFTB5SQQo2zCecljny'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "MU=pd.read_csv(open('MU-token.csv','rU'),sep=',')\n",
    "MC=pd.read_csv(open('MC-token.csv','rU'),sep=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    " \n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + ['rt', 'via','…','’','RT']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('manchester', 86656), ('city', 80419), ('arsenal', 22930), ('1', 12642), ('united', 10479), ('w', 9121), ('league', 8202), ('vs', 7725), ('new', 7087), ('sergio', 6515), (\"city's\", 6129), ('3', 5646), ('man', 5445), ('mayor', 5407), ('aguero', 5377), ('says', 5270), ('time', 5123), ('still', 5015), ('live', 4991), ('premier', 4921)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('manchester', 86157), ('united', 83403), ('@manutd', 14161), ('#mufc', 10711), ('alex', 10282), ('sir', 10056), ('ferguson', 10045), ('manager', 9833), ('mourinho', 9154), ('years', 8344), ('31', 8138), ('ago', 7969), ('chelsea', 7814), ('£', 7783), ('league', 7646), ('today', 7323), ('jose', 7229), ('became', 7014), ('https://t.co/ssjfpgilcz', 6650), ('madrid', 6293)]\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "import json\n",
    "from collections import Counter\n",
    " \n",
    "count_all_MC = Counter()\n",
    "for i in range(len(MC)):\n",
    "    tweet = MC.iloc[i]\n",
    "        # Create a list with all the terms\n",
    "    MC['token_stop_lower'][i] = [term for term in preprocess(str(tweet['text'])) if term not in stop]\n",
    "        # Update the counter\n",
    "    count_all_MC.update(MC['token_stop_lower'][i])\n",
    "    # Print the first 5 most frequent words\n",
    "print(count_all_MC.most_common(20))\n",
    "\n",
    "count_all_MU = Counter()\n",
    "for i in range(len(MU)):\n",
    "    tweet = MU.iloc[i]\n",
    "        # Create a list with all the terms\n",
    "    MU['token_stop_lower'][i] = [term for term in preprocess(str(tweet['text'])) if term not in stop]\n",
    "        # Update the counter\n",
    "    count_all_MU.update(MU['token_stop_lower'][i])\n",
    "    # Print the first 5 most frequent words\n",
    "print(count_all_MU.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MC.to_csv(\"MC-token-l.csv\",index=False,sep=',')\n",
    "MU.to_csv(\"MU-token-l.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams \n",
    " \n",
    "terms_bigram = bigrams(terms_stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
