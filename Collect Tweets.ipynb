{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "consumer_key = 'UKw2KLxameeRC2eUuMJVjdnaM'\n",
    "consumer_secret = 'llDfpCz90ye74A3VL3bJdoASXMzNTTOgYyOfBWGUOnActXUYf7'\n",
    "access_token = '927148475950751746-jPlH5nynmPNLzStdmlepsmDAmHKWVGB'\n",
    "access_token_secret = '2R2P1ChKmmFsyqIMZwfOC461MPawFTB5SQQo2zCecljny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 1000 tweets\n",
      "Downloaded 100 tweets\n",
      "Downloaded 200 tweets\n",
      "Downloaded 300 tweets\n",
      "Downloaded 398 tweets\n",
      "Downloaded 498 tweets\n",
      "Downloaded 598 tweets\n",
      "Downloaded 698 tweets\n",
      "Downloaded 798 tweets\n",
      "Downloaded 898 tweets\n",
      "Downloaded 998 tweets\n",
      "Downloaded 1098 tweets\n",
      "Downloaded 1098 tweets, Saved to ManchesterCity.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "searchQuery ='Manchester City'\n",
    "#searchQuery = ['#Old trafford','#Manchester United', '#ROMELU LUKAKU', '#JOSE MOURINHO', '#Man Utd', '#PAUL POGBA','#Manchester City','#VINCENT KOMPANY','#PEP GUARDIOLA','#Etihad']\n",
    "# this is what we're searching for\n",
    "maxTweets = 1000 # Some arbitrary large number\n",
    "tweetsPerQry = 100  # this is the max the API permits\n",
    "fName = 'ManchesterCity.json' # We'll store the tweets in a text file.\n",
    "\n",
    "\n",
    "# If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "# else default to no lower limit, go as far back as API allows\n",
    "sinceId = None\n",
    "\n",
    "# If results only below a specific ID are, set max_id to that ID.\n",
    "# else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "max_id =-1\n",
    "\n",
    "tweetCount = 0\n",
    "print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "with open(fName, 'a',encoding=\"utf-8\") as f:\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,lang='en')\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            since_id=sinceId,lang='en')\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1),lang='en')\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1),\n",
    "                                            since_id=sinceId,lang='en')\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                f.write(json.dumps(tweet._json)+str('\\n'))\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "\n",
    "print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95012\n",
      "95012\n",
      "100048\n",
      "100048\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "MU=[]\n",
    "with open('ManchesterUnited-en.json', 'r') as f:\n",
    "    line = f.readlines() # read only the first tweet/line\n",
    "    print(len(line))\n",
    "    for i in line:\n",
    "        tweet= json.loads(i) # load it as Python dict\n",
    "        MU.append((tweet['user']['screen_name'],tweet['text'],tweet['geo'],tweet['user']['location'],tweet['user']['followers_count'],tweet['user']['friends_count'],tweet['created_at']))\n",
    "print(len(MU))\n",
    "\n",
    "MC=[]\n",
    "with open('ManchesterCity-en.json', 'r') as f:\n",
    "    line = f.readlines() # read only the first tweet/line\n",
    "    print(len(line))\n",
    "    for i in line:\n",
    "        tweet= json.loads(i) # load it as Python dict\n",
    "        MC.append((tweet['user']['screen_name'],tweet['text'],tweet['geo'],tweet['user']['location'],tweet['user']['followers_count'],tweet['user']['friends_count'],tweet['created_at']))\n",
    "print(len(MC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "MCdf=pd.DataFrame(columns=['user','text','geo','location','followers_count','friends_count','created_at'])  \n",
    "MUdf=pd.DataFrame(columns=['user','text','geo','location','followers_count','friends_count','created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(MU)):\n",
    "    MUdf.loc[i]={'user':MU[i][0],'text':MU[i][1],'geo':MU[i][2],'location':MU[i][3],'followers_count':MU[i][4],'friends_count':MU[i][5],\"created_at\":MU[i][6]}\n",
    "for i in range(len(MC)):\n",
    "    MCdf.loc[i]={'user':MC[i][0],'text':MC[i][1],'geo':MC[i][2],'location':MC[i][3],'followers_count':MC[i][4],'friends_count':MC[i][5],\"created_at\":MC[i][6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MCdf.to_csv(\"MC-en.csv\",index=False,sep=',')\n",
    "MUdf.to_csv(\"MU-en.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORDS = ['#Old trafford',\n",
    "         '#Manchester United', \n",
    "         '#ROMELU LUKAKU', \n",
    "         '#JOSE MOURINHO', \n",
    "         '#Man Utd', \n",
    "         '#PAUL POGBA',\n",
    "         '#Manchester City',\n",
    "         '#VINCENT KOMPANY',\n",
    "         '#PEP GUARDIOLA',\n",
    "         '#Etihad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
